---
title: "Similraity"
format: html
---

```{r}
library("readr")
library("dplyr")
library("sf")
```

```{r}
wildschwein <- read_delim("wildschwein_BE_2056.csv", ",")
```

```{r}
# Careful! What Timezone is assumed?
sabi <- wildschwein |>
    st_as_sf(coords = c("E", "N"), crs = 2056, remove = FALSE) |>
    filter(TierName == "Sabi", DatetimeUTC >= "2015-07-01", DatetimeUTC < "2015-07-03")
```

GGPLOT
```{r}
library(ggplot2)

ggplot(sabi, aes(E,N, color = DatetimeUTC))+
  geom_point()+
  geom_path()+
  coord_fixed() +
  scale_color_datetime(low = "blue", high = "red")+
  guides(color = guide_colorbar(title.position = "top", title.hjust= .5, barwidth= unit(2)))
```

# Distance measure for window v and segmentation
```{r}
distance_by_element <- function(later, now) {
  as.numeric(
    st_distance(later, now, by_element = TRUE)
  )
}

sabi <- sabi |>
    mutate(
        nMinus2 = distance_by_element(lag(geometry, 2), geometry),  # distance to pos -30 minutes
        nMinus1 = distance_by_element(lag(geometry, 1), geometry),  # distance to pos -15 minutes
        nPlus1  = distance_by_element(geometry, lead(geometry, 1)), # distance to pos +15 mintues
        nPlus2  = distance_by_element(geometry, lead(geometry, 2))  # distance to pos +30 minutes
    )

sabi <- sabi |>
    rowwise() |>
    mutate(
        stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))
    ) |>
    ungroup()

sabi
```

# Remove static points
```{r}
sabi <- sabi |>
    mutate(static = stepMean < mean(stepMean, na.rm = TRUE))

sabi_filter <- sabi |>
    filter(!static)

sabi_filter |>
    ggplot(aes(E, N)) +
    geom_path() +
    geom_point() +
    coord_fixed() +
    theme(legend.position = "bottom")
```

# Load my own data

```{r}
install.packages("XML")
library(XML)

gpx_to_df <- function(gpx_path) {
  
  gpx_parsed <- htmlTreeParse(file = gpx_path, useInternalNodes = TRUE)
  
  # read out elements of the html file to vecotrs
coords <- xpathSApply(doc = gpx_parsed, path = "//trkpt", fun = xmlAttrs)
elevation <- xpathSApply(doc = gpx_parsed, path = "//trkpt/ele", fun = xmlValue)
time <- xpathSApply(doc = gpx_parsed, path = "//time", fun = xmlValue)
activity_name <- xpathSApply(doc = gpx_parsed, path = "//name", fun = xmlValue)


# remove first value of time, as it stems from the metadata and matches the second value (i.e. first timestamp of trackpoint)
time <- time[-1]

# convert vectors to a data frame
df <- data.frame(
  lat = as.numeric(coords["lat", ]),
  lon = as.numeric(coords["lon", ]),
  elevation = as.numeric(elevation), 
  timestamp = as.POSIXct(time,tz="UTC", format=c("%Y-%m-%dT%H:%M:%OS")),
  ActivityName = activity_name 
) 

dfname <- print(substring(gpx_path, 12, 34))

assign(dfname, df, envir = .GlobalEnv)
}
```

Apply function to all gpx-files from strava-folder: 
```{r}
# Get a list of files in the folder
folder_path <- "activities/"
file_list <- list.files(folder_path, full.names = TRUE)

# Iterate over each file and apply your function
for (file_path in file_list) {
  gpx_to_df(file_path)
}
```

# Combine single track-files to one Dataframe
Here I stitch the single dataframes containing the tracks' information together 
```{r}
#create a list of the df names
dflist <- substring(file_list,12,34)

all_tracks <- do.call(rbind, lapply(dflist, get))
```

The metadata from the 'activity' dataframe is not of any additional use. It is thus not stitched to the track data. 

# Converting the df to sf object
I convert the given dataframe to an sf-object for better handling of the spatial data and for being able to do metric calculations (ex. for distance). For this, the function needs an argument specifiying the columns that hold the spatial data, as well as the information as to which crs is being used. Here it is the lat/long crs, which is EPSG:4326 or WGS 84. 
Here it is important to specify first the longitude and then the latitude, as it is the standard convention. 

```{r}
library(sf)
all_tracks <- st_as_sf(all_tracks, coords = c("lon", "lat"), crs = 4326)
str(all_tracks)
```

## Transforming the crs 
We would like the CRS to be in the format of CH1903 +LV95 or EPSG:2056
```{r}
all_tracks <- st_transform(all_tracks, 2056)
str(all_tracks)


# Check Timezone
attr(all_tracks$timestamp, "tzone")
```

## Filtering out old data
```{r}
library(dplyr)
library(lubridate)
all_tracks <- all_tracks |> 
  mutate("year" = year(timestamp)) |> 
  filter(year == 2024)
```

# Making a map of the data
```{r}
library(tmap)

tmap_mode("view")

  tm_shape(all_tracks)+
  tm_dots(col = "ActivityName") 
```

# ex 4

## Adding coordinates 
```{r}
st_coordinates(all_tracks)

tracks <- cbind(all_tracks,st_coordinates(all_tracks))
```

## Filtern 
```{r}
home <- tracks |> filter(ActivityName == "Home")
```

## Dataexploration of example track

```{r}
library(ggplot2)

# Duration of recording
difftime(max(home$timestamp, na.rm = T), min(home$timestamp, na.rm = T))

# Sampling frequency
difftime_secs <- function(later, now){
    as.numeric(difftime(later, now, units = "secs"))
}

home <- home |> 
  mutate(timelag = difftime_secs(lead(timestamp), timestamp))

boxplot(home$timelag)
summary(home$timelag)25

home |> 
  ggplot(aes(timestamp, timelag)) + 
  geom_point()
```

The largest part of the given timestamps was recorded with an interval of 1-second. There are a few outliers with an interval of up to 331 seconds (i.e. 5.5 min) and they mainly occur in the second half of the recording. The duration of the recording is one hour. At this point, one could try out different temporal window specifications. I will chose a temporal window of half a minute, thus including 30 fixes or 30 seconds (except for outliers). 

We need to calculate the following Euclidean distances (pos representing single location):
  
- pos[n-30] to pos[n]
- pos[n-30] to pos[n]
- pos[n] to pos[n+30]
- pos[n] to pos[n+30]

Für die Distanzrechnung nutzt man st_distance mit dem Argument by_element = T.
Um die Unit Meter los zu werden würden wir diese Zeilen noch mit as.numeric versehen. 
Einfacher geht es mit einer Funktion:

## Step a): Specify a temporal window 
Step b): Measure the distance from every point to every other point within this temporal window 
We can use the function distance_by_element from week 2 in combination with lead() and lag() to calculate the Euclidean distance. For example, to create the necessary offset of n-2, we use lag(x, 2). For each offset, we create one individual column.

Now we want to calculate the mean distance of nMinus2, nMinus1, nPlus1, nPlus2 for each row. Since we want the mean value per Row, we have to explicitly specify this before mutate() with the function rowwise(). To remove this rowwise-grouping, we end the operation with ungroup().

```{r}
library(sf)

# We need to calculate the following Euclidean distances (pos representing single location):
# Distance btw. PointsFuntion
distance_by_element <- function(later, now){
  as.numeric(
    st_distance(later, now, by_element = TRUE)
  )
  }

home <- home |> mutate(
  nMinus30 = distance_by_element(lag(geometry, n=30), geometry), # distance to pos -30 seconds
  nMinus15 = distance_by_element(lag(geometry, n=15), geometry), # distance to pos -15 seconds
  nPlus15 = distance_by_element(lead(geometry, n=15), geometry), # distance to pos +15 seconds
  nPlus30 = distance_by_element(lead(geometry, n=30), geometry)  # distance to pos +30 seconds
)

summary(home$nMinus30)
```


Note that for the first two positions, we cannot calculate a stepMean since there is no Position n-2 for these positions. This is also true for the last to positions (lacking a position n+2).

```{r}
home <- home |>
    rowwise() |>
    mutate(
        stepMean = mean(c(nMinus30, nMinus15, nPlus15, nPlus30))
    ) |>
    ungroup()

home
```

## Step c): Remove “static points”
We can now determine if an animal is moving or not by specifying a threshold distance on stepMean. In our example, we use the mean value as a threshold: Positions with distances below this value are considered static.
