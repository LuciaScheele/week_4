---
title: "Similraity"
format: html
---

```{r}
library("readr")
library("dplyr")
library("sf")
```

```{r}
wildschwein <- read_delim("wildschwein_BE_2056.csv", ",")
```

```{r}
# Careful! What Timezone is assumed?
sabi <- wildschwein |>
    st_as_sf(coords = c("E", "N"), crs = 2056, remove = FALSE) |>
    filter(TierName == "Sabi", DatetimeUTC >= "2015-07-01", DatetimeUTC < "2015-07-03")
```

GGPLOT
```{r}
library(ggplot2)

ggplot(sabi, aes(E,N, color = DatetimeUTC))+
  geom_point()+
  geom_path()+
  coord_fixed() +
  scale_color_datetime(low = "blue", high = "red")+
  guides(color = guide_colorbar(title.position = "top", title.hjust= .5, barwidth= unit(2)))
```

# Distance measure for window v and segmentation
```{r}
distance_by_element <- function(later, now) {
  as.numeric(
    st_distance(later, now, by_element = TRUE)
  )
}

sabi <- sabi |>
    mutate(
        nMinus2 = distance_by_element(lag(geometry, 2), geometry),  # distance to pos -30 minutes
        nMinus1 = distance_by_element(lag(geometry, 1), geometry),  # distance to pos -15 minutes
        nPlus1  = distance_by_element(geometry, lead(geometry, 1)), # distance to pos +15 mintues
        nPlus2  = distance_by_element(geometry, lead(geometry, 2))  # distance to pos +30 minutes
    )

sabi <- sabi |>
    rowwise() |>
    mutate(
        stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))
    ) |>
    ungroup()

sabi
```

# Remove static points
```{r}
sabi <- sabi |>
    mutate(static = stepMean < mean(stepMean, na.rm = TRUE))

sabi_filter <- sabi |>
    filter(!static)

sabi_filter |>
    ggplot(aes(E, N)) +
    geom_path() +
    geom_point() +
    coord_fixed() +
    theme(legend.position = "bottom")
```

# Load my own data

```{r}
install.packages("XML")
library(XML)

gpx_to_df <- function(gpx_path) {
  
  gpx_parsed <- htmlTreeParse(file = gpx_path, useInternalNodes = TRUE)
  
  # read out elements of the html file to vecotrs
coords <- xpathSApply(doc = gpx_parsed, path = "//trkpt", fun = xmlAttrs)
elevation <- xpathSApply(doc = gpx_parsed, path = "//trkpt/ele", fun = xmlValue)
time <- xpathSApply(doc = gpx_parsed, path = "//time", fun = xmlValue)
activity_name <- xpathSApply(doc = gpx_parsed, path = "//name", fun = xmlValue)


# remove first value of time, as it stems from the metadata and matches the second value (i.e. first timestamp of trackpoint)
time <- time[-1]

# convert vectors to a data frame
df <- data.frame(
  lat = as.numeric(coords["lat", ]),
  lon = as.numeric(coords["lon", ]),
  elevation = as.numeric(elevation), 
  timestamp = as.POSIXct(time,tz="UTC", format=c("%Y-%m-%dT%H:%M:%OS")),
  ActivityName = activity_name 
) 

dfname <- print(substring(gpx_path, 12, 34))

assign(dfname, df, envir = .GlobalEnv)
}
```

Apply function to all gpx-files from strava-folder: 
```{r}
# Get a list of files in the folder
folder_path <- "activities/"
file_list <- list.files(folder_path, full.names = TRUE)

# Iterate over each file and apply your function
for (file_path in file_list) {
  gpx_to_df(file_path)
}
```

# Combine single track-files to one Dataframe
Here I stitch the single dataframes containing the tracks' information together 
```{r}
#create a list of the df names
dflist <- substring(file_list,12,34)

all_tracks <- do.call(rbind, lapply(dflist, get))
```

The metadata from the 'activity' dataframe is not of any additional use. It is thus not stitched to the track data. 

# Converting the df to sf object
I convert the given dataframe to an sf-object for better handling of the spatial data and for being able to do metric calculations (ex. for distance). For this, the function needs an argument specifiying the columns that hold the spatial data, as well as the information as to which crs is being used. Here it is the lat/long crs, which is EPSG:4326 or WGS 84. 
Here it is important to specify first the longitude and then the latitude, as it is the standard convention. 

```{r}
library(sf)
all_tracks <- st_as_sf(all_tracks, coords = c("lon", "lat"), crs = 4326)
str(all_tracks)
```

## Transforming the crs 
We would like the CRS to be in the format of CH1903 +LV95 or EPSG:2056
```{r}
all_tracks <- st_transform(all_tracks, 2056)
str(all_tracks)


# Check Timezone
attr(all_tracks$timestamp, "tzone")
```

## Filtering out old data
```{r}
library(dplyr)
library(lubridate)
all_tracks <- all_tracks |> 
  mutate("year" = year(timestamp)) |> 
  filter(year == 2024)
```

# Making a map of the data
```{r}
library(tmap)

tmap_mode("view")

  tm_shape(all_tracks)+
  tm_dots(col = "ActivityName") 
```

# ex 4

## Adding coordinates 
```{r}
st_coordinates(all_tracks)

tracks <- cbind(all_tracks,st_coordinates(all_tracks))
```

## Filtern 
```{r}
home <- tracks |> filter(ActivityName == "Home")
```

## Dataexploration of example track

```{r}
library(ggplot2)

# Duration of recording
difftime(max(home$timestamp, na.rm = T), min(home$timestamp, na.rm = T))

# Sampling frequency
difftime_secs <- function(later, now){
    as.numeric(difftime(later, now, units = "secs"))
}

home <- home |> 
  mutate(timelag = difftime_secs(lead(timestamp), timestamp))

boxplot(home$timelag)
summary(home$timelag)

home |> 
  ggplot(aes(timestamp, timelag)) + 
  geom_point()
```

The largest part of the given timestamps was recorded with an interval of 1-second. There are a few outliers with an interval of up to 331 seconds (i.e. 5.5 min) and they mainly occur in the second half of the recording. The duration of the recording is one hour. 

## Step a): Specify a temporal window 
At this point, one could try out different temporal window specifications. I will choose a temporal window of 10 seconds around a fix and a sample of 4 distances.

We need to calculate the following Euclidean distances (pos representing single location):
  
- pos[n-5] to pos[n]
- pos[n-2] to pos[n]
- pos[n] to pos[n+2]
- pos[n] to pos[n+5]

Für die Distanzrechnung nutzt man st_distance mit dem Argument by_element = T.
Um die Unit Meter los zu werden würden wir diese Zeilen noch mit as.numeric versehen. 
Einfacher geht es mit einer Funktion.

## Step b): Measure the distance from every point to every other point within this temporal window 
We can use the function distance_by_element from week 2 in combination with lead() and lag() to calculate the Euclidean distance. For example, to create the necessary offset of n-2, we use lag(x, 2). For each offset, we create one individual column.

```{r}
library(sf)

# We need to calculate the following Euclidean distances (pos representing single location):
# Distance btw. PointsFuntion
distance_by_element <- function(later, now){
  as.numeric(
    st_distance(later, now, by_element = TRUE)
  )
  }

home <- home |> mutate(
  nMinus5 = distance_by_element(lag(geometry, n=5), geometry), # distance to pos -5 seconds
  nMinus2 = distance_by_element(lag(geometry, n=2), geometry), # distance to pos -2 seconds
  nPlus2 = distance_by_element(geometry, lead(geometry, n=2)), # distance to pos +2 seconds
  nPlus5 = distance_by_element(geometry, lead(geometry, n=5))  # distance to pos +5 seconds
)

summary(home$nMinus5)
```

Now we want to calculate the mean distance of nMinus5, nMinus2, nPlus2, nPlus5 for each row. Since we want the mean value per Row, we have to explicitly specify this before mutate() with the function rowwise(). To remove this rowwise-grouping, we end the operation with ungroup().

Note that for the first two positions, we cannot calculate a stepMean since there is no Position n-2 for these positions. This is also true for the last to positions (lacking a position n+2).

```{r}
home <- home |>
    rowwise() |>
    mutate(
        stepMean = mean(c(nMinus5, nMinus2, nPlus2, nPlus5))
    ) |>
    ungroup()

home 
```

# Task 2: Specify and apply threshold d
After calculating the Euclidean distances to positions within the temporal window v in task 1, you can explore these values (we stored them in the column stepMean) using summary statistics (histograms, boxplot, summary()): This way we can define a reasonable threshold value to differentiate between stops and moves. There is no “correct” way of doing this, specifying a threshold always depends on data as well as the question that needs to be answered. In this exercise, use the mean of all stepMean values.

Store the new information (boolean to differentiate between stops (TRUE) and moves (FALSE)) in a new column named static.


```{r}
hist(home$stepMean)
boxplot(home$stepMean)
summary(home$stepMean)

home <- home |> 
  mutate(static = stepMean < mean(stepMean, na.rm = TRUE)) 

```
Commit your changes with a meaningful commit message.

## Task 3: Visualize segmented trajectories
Now visualize the segmented trajectory spatially. Just like last week, you can use ggplot with geom_path(), geom_point() and coord_equal(). Assign colour = static within aes() to distinguish between segments with “movement” and without.

```{r}
home_filter <- home |>
    filter(!static)

home_filter |>
    ggplot(aes(X, Y)) +
    geom_path() +
    geom_point() +
    coord_fixed() +
    theme(legend.position = "bottom")
```

## Task 4: Segment-based analysis
In applying Laube and Purves (2011), we’ve come as far as step b) in Figure 14.1. In order to complete the last steps (c and d), we need a unique ID for each segment that we can use as a grouping variable. The following function does just that (it assigns unique IDs based on the column static which you created in Task 2). You will learn about functions next week. For now, just copy the following code chunk into your script and run it.

### Unique IDs
```{r}
rle_id <- function(vec) {
    x <- rle(vec)$lengths
    as.factor(rep(seq_along(x), times = x))
}
```

You can use the newly created function rle_id to assign unique IDs to subtrajectories (as shown below). 

```{r}
home <- home |>
  mutate(segment_id = rle_id(static))
```

The df of my track now contains a column of IDs that are allocated to segments by differentiating between static (true) and non.static (false) segements. 

### Visualize the moving segments 
by colourizing them by segment_ID. Then use segment_ID as a grouping variable to determine the segments duration and remove short segments (e.g. segments with a duration < 5 Minutes)

```{r}
home |>
    ggplot(aes(X, Y)) +
    geom_path() +
    geom_point(aes(colour = segment_id)) +
    coord_fixed() +
    theme(legend.position = "bottom") +
 theme(legend.position = "none")
```

### Segment duration

```{r}
# Duration of segments 
difftime_secs_by_element <- function(later, now){
    as.numeric(difftime(later, now, units = "secs"), by_element = T)
}

home <- home |> 
  group_by(segment_id) |> 
  mutate(duration = difftime_secs_by_element(max(timestamp), min(timestamp)))

# Summary of Segment duration in minutes
summary(c(home$duration/60))
boxplot(c(home$duration/60))
```

It is not clear whay we did this step with static segments included. I thus want to keep working with only dynamic segments. 

#### Try out for only dynamic data
```{r}
home_filter <- home |> 
  filter(static== FALSE) |> 
  group_by(segment_id) |> 
  mutate(duration = difftime_secs_by_element(max(timestamp), min(timestamp)))

# Summary of Segment duration in minutes
summary(c(home_filter$duration/60))
boxplot(c(home_filter$duration/60))
```

### Remove short segments
I would like to look at movement segments longer than a minute, so I will remove the segments with a duration of less than 60 seconds. 

```{r}
home_filter_cleaned <- home_filter |>  
  filter(duration >= 60)

home_filter_cleaned |>
  group_by(segment_id) |> 
    ggplot(aes(X, Y)) +
    geom_path() +
    geom_point(aes(colour = segment_id)) +
    coord_fixed() +
    theme(legend.position = "bottom") +
 theme(legend.position = "none")
```

Commit your changes with a meaningful commit message.

## Task 5: Similarity measures
We will now calculate similarties between trajectories using a new dataset pedestrian.csv. Download an import this dataset as a data.frame or tibble. It it a set of six different but similar trajectories from pedestrians walking on a path.

### Data Import
```{r}
pedestrian <- read_delim("pedestrian.csv", delim = ",") |> 
  st_as_sf(coords = c("E", "N"), crs = 2056, remove = FALSE)
```

### Exploration of Data
```{r}
pedestrian |> 
  ggplot(aes(E,N))+
  geom_point(aes(colour = TrajID)) +
  geom_line() +
  facet_wrap(vars(TrajID))
```

From this visualisation, we can already see that there are differences in the sampling frequency and spacial extension of the trajectory fixes. 

An interesting observation is in the trajIDs 4 and 5, where strongly diverging. In the case of 5, it could be a geometric outlier problem. In the case of 4, there appears to be some timestamp issue. 

For further comparisons, it would be important to know more about the temporal scales of the trajectories, i.e. duration, timelag, and length. 

```{r}
# length/ amount of fixes per trajectories 
count <- pedestrian |> 
  group_by(TrajID) |> 
  summarise(count= n())

duration <- pedestrian |> 
  group_by(TrajID) |> 
  summarise(duration = max(DatetimeUTC) - min(DatetimeUTC))

# sampling frequency (timelag)
pedestrian <- pedestrian |> 
  mutate(timelag = difftime_secs(lead(DatetimeUTC), DatetimeUTC))

boxplot(pedestrian$timelag)
summary(pedestrian$timelag)

pedestrian |> 
  filter(timelag > c(-2000)) |> 
  ggplot(aes(DatetimeUTC, timelag)) + 
  geom_point() +
  facet_wrap(vars(TrajID))

# Duration
pedestrian |> group_by(TrajID) |> 
  summarize(duration = difftime_secs(max(DatetimeUTC, na.rm = T), min(DatetimeUTC, na.rm = T)))

difftime(max(home$timestamp, na.rm = T), min(home$timestamp, na.rm = T))
```

Die gegebenen Trajectories haben eine Sampling frequency von 60 Sekunden, wobei die Anzahl der Aufgenommenen Fixes (von 45 bis 51 Fixes/Trajectory) und die Dauer der Aufnahme (von 2700 bis 3060) variieieren.


